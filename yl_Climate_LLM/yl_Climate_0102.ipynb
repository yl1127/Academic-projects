{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a516e51-795a-4598-843f-36d8fd7f3221",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Here's the result about how to use different Input prompts to answer the climate questions Q1.\n",
    "\n",
    "The questions are from [chatClimate: Grounding Conversational AI in Climate Science](https://arxiv.org/abs/2304.05510)\n",
    "\n",
    "The Climate report is from [IPCC_AR6_WGIII_FullReport](https://sdgs.un.org/sites/default/files/2023-01/IPCC_AR6_WGIII_FullReport.pdf)\n",
    "\n",
    "The Llama2(Original), Llama2+(Climate report) and **Llama2 hybird** code parts are available [here](https://github.com/yl1127/Academic-projects/blob/main/yl_Climate_LLM/yl_LlamaCloud_Climate.ipynb).\n",
    "\n",
    "\n",
    "(12.18)The Llama2(Original) and Llama2+(Climate report) code parts are available [here](https://github.com/yl1127/Academic-projects/blob/main/yl_Climate_LLM/yl_LlamaCloud_Climate.ipynb).\n",
    "\n",
    "The ChatGPT3.5(Original) is available [here](https://chat.openai.com/share/17cf5cc6-50db-4547-a56f-18756a974622).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14baf22-8c82-499d-8371-fa991679d3a6",
   "metadata": {},
   "source": [
    "| Result | Llama2(Original) | GPT3.5(Original) | Llama2 +(Climate report)|Llama2 hybird|\n",
    "| ----------- | ----------- |------------------|-------------------------|-----------------------|\n",
    "|Q1: Is it still possible to limit warming to 1.5°C?| Regarding your question, \"Is it still possible to limit warming to 1.5°C?\" the answer is yes, but it will require significant and immediate action from governments, businesses, and individuals around the world. According to the Intergovernmental Panel on Climate Change (IPCC), limiting global warming to 1.5°C above pre-industrial levels is still technically and economically feasible, but it will require a concerted effort to reduce greenhouse gas emissions by 45% by 2030 and reach net-zero emissions by 2050. To achieve this goal, we need to see a rapid transition away from fossil fuels and towards renewable energy sources such as solar and wind power. We also need to increase energy efficiency, electrify transportation, and implement carbon capture and storage technologies. Furthermore, protecting and reforestation efforts can help remove carbon dioxide from the atmosphere, and sustainable land use practices can help sequester carbon in soils and biomass. However, the window of opportunity for limiting warming to 1.5°C is rapidly closing. The IPCC has warned that if global warming exceeds 1.5°C, the risk of extreme weather events such as heatwaves, droughts, and heavy rainfall increases, and the likelihood of reaching tipping points such as melting glaciers and sea level rise increases. Therefore, it is crucial that we take urgent action now to address climate change and avoid the worst impacts of global warming. This includes implementing policies such as carbon pricing, increasing investment in clean energy, and promoting sustainable development and consumption patterns. |As of my last knowledge update in January 2022, achieving the goal of limiting global warming to 1.5°C above pre-industrial levels, as set out in the Paris Agreement, was considered extremely challenging. The Intergovernmental Panel on Climate Change (IPCC) released a special report in 2018 that highlighted the significant differences between a 1.5°C and a 2°C warmer world in terms of climate impacts. Meeting the 1.5°C target requires rapid, far-reaching, and unprecedented changes across all aspects of society, including energy, land use, transportation, and industry. It would necessitate substantial reductions in greenhouse gas emissions and a transition to a more sustainable and low-carbon global economy. Efforts to limit warming to 1.5°C would require countries to strengthen their commitments and actions to reduce emissions. Additionally, the use of technologies for carbon capture and removal might be necessary. The success of such efforts would also depend on international cooperation and collective action. It's important to note that developments may have occurred since my last update, and the situation may have evolved. I recommend checking for the latest information from reputable sources, such as reports from the IPCC or other climate organizations, for the most up-to-date assessment of efforts to limit global warming to 1.5°C.| According to the information provided, the possibility of limiting warming to 1.5°C is still present, but it will require significant efforts to achieve this goal. The Intergovernmental Panel on Climate Change (IPCC) has outlined several pathways that could lead to limiting global warming to 1.5°C above pre-industrial levels, which include: 1. Reducing greenhouse gas emissions by 45% by 2030 and reaching net-zero emissions by 2050. 2. Increasing the use of renewable energy sources such as solar and wind power. 3. Improving energy efficiency and reducing wasteful consumption. 4. Protecting and reforestation efforts to remove carbon dioxide from the atmosphere. However, it is important to note that achieving these goals will require the cooperation and commitment of governments, businesses, and individuals around the world. It will also require significant investments in clean energy technologies and infrastructure, as well as changes in individual behavior and consumer choices. | To provide the most accurate answer, I would like to refer to the Intergovernmental Panel on Climate Change (IPCC) Sixth Assessment Report (AR6), which states that limiting global warming to 1.5°C is technically and financially feasible, but it requires significant and rapid reductions in greenhouse gas emissions. The report emphasizes that the window for achieving this goal is rapidly closing (IPCC AR6, p. 3). However, it is important to note that achieving the 1.5°C target will become increasingly challenging as time passes, as the concentration of greenhouse gases in the atmosphere continues to rise. According to the IPCC, the world has already warmed by about 1°C since preindustrial times, and the amount of greenhouse gases in the atmosphere has increased by about 40% since the mid-1800s (IPCC AR6, p. 17). Furthermore, the IPCC reports that there are significant differences between the impacts of 1.5°C and 2°C of warming. For example, at 1.5°C, sea level rise is projected to be around 20-30 cm lower than at 2°C, and the risk of coral reefs dying off is significantly higher at 2°C than at 1.5°C (IPCC AR6, pp. 19-20). In conclusion, while limiting warming to 1.5°C is technically and financially feasible, it requires urgent action and significant reductions in greenhouse gas emissions. The longer we delay taking action, the more difficult it will become to achieve this goal. Therefore, I strongly advise policymakers and other stakeholders to take immediate and drastic measures to reduce emissions and prevent further warming. (IPCC AR6)|\n",
    "| rate| -------------- |------------------|-------------------------|-----------------------|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1ea03a-cc69-45b0-80d3-664e48ca6831",
   "metadata": {},
   "source": [
    "## This demo app shows:\n",
    "* How to run Llama2 in the cloud hosted on Replicate\n",
    "* How to use LangChain to ask Llama general questions and follow up questions\n",
    "* How to use LangChain to load a recent PDF doc - This is the well known RAG (Retrieval Augmented Generation) method to let LLM such as Llama2 be able to answer questions about the data not publicly available when Llama2 was trained, or about your own data. RAG is one way to prevent LLM's hallucination\n",
    "* How to use LangChain to load a directory which includes multiple PDF docs.\n",
    "* You should also review the [HelloLlamaLocal](HelloLlamaLocal.ipynb) notebook for more information on RAG\n",
    "\n",
    "**Note** We will be using Replicate to run the examples here. You will need to first sign in with Replicate with your github account, then create a free API token [here](https://replicate.com/account/api-tokens) that you can use for a while. \n",
    "After the free trial ends, you will need to enter billing info to continue to use Llama2 hosted on Replicate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dde626",
   "metadata": {},
   "source": [
    "Let's start by installing the necessary packages:\n",
    "- sentence-transformers for text embeddings\n",
    "- chromadb gives us database capabilities \n",
    "- langchain provides necessary RAG tools for this demo\n",
    "\n",
    "And setting up the Replicate token."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cd8508-c8b8-4cd2-be26-01b97e664ff9",
   "metadata": {},
   "source": [
    "### How to run original Llama2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c608df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain replicate sentence-transformers chromadb pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9c5546a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "from getpass import getpass\n",
    "import os\n",
    "\n",
    "REPLICATE_API_TOKEN = getpass()\n",
    "os.environ[\"REPLICATE_API_TOKEN\"] = REPLICATE_API_TOKEN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8870c1",
   "metadata": {},
   "source": [
    "Next we call the Llama 2 model from replicate. In this example we will use the llama 2 13b chat model. You can find more Llama 2 models by searching for them on the [Replicate model explore page](https://replicate.com/explore?query=llama).\n",
    "\n",
    "You can add them here in the format: model_name/version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad536adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Replicate\n",
    "\n",
    "llama2_13b = \"meta/llama-2-13b-chat:f4e2de70d66816a838a89eeeb621910adffb0dd0baba3976c96980970978018d\"\n",
    "\n",
    "# llm = Replicate(\n",
    "#     model=llama2_13b,\n",
    "#     model_kwargs={'prompt': f\"{string_dialogue} {question} Assistant: \", \"temperature\": 0.01, \"top_p\": 1, \"max_new_tokens\":5000},\n",
    "#     # max_tokens = 2000,\n",
    "#     # n_ctx=4000,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f6a9806-ce38-4649-9a43-4db7c0365338",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Is it still possible to limit warming to 1.5°C?\" #Q1\n",
    "\n",
    "input_prompt = {\n",
    "    \"system\": {\n",
    "        \"content\": \"You are Q&A bot. A highly intelligent system that answers user questions\"\n",
    "    },\n",
    "    \"role\": \"user\",\n",
    "    \"content\": question\n",
    "}\n",
    "\n",
    "llm = Replicate(\n",
    "    model=llama2_13b,\n",
    "    model_kwargs={'prompt': f\"{input_prompt}\", \"temperature\": 0.01, \"top_p\": 1, \"max_new_tokens\":5000},\n",
    "    # max_tokens = 2000,\n",
    "    # n_ctx=4000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd207c80",
   "metadata": {},
   "source": [
    "With the model set up, you are now ready to ask some questions. Here is an example of the simplest way to ask the model some general questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e078957-b820-4808-8e6d-813b639bb202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hello! As your helpful assistant, I'm here to provide you with the most up-to-date and accurate information on climate change and its impacts.\n",
      "\n",
      "Regarding your question, \"Is it still possible to limit warming to 1.5°C?\" the answer is yes, but it will require significant and immediate action from governments, businesses, and individuals around the world.\n",
      "\n",
      "According to the Intergovernmental Panel on Climate Change (IPCC), limiting global warming to 1.5°C above pre-industrial levels is still technically and economically feasible, but it will require a concerted effort to reduce greenhouse gas emissions by 45% by 2030 and reach net-zero emissions by 2050.\n",
      "\n",
      "To achieve this goal, we need to see a rapid transition away from fossil fuels and towards renewable energy sources such as solar and wind power. We also need to increase energy efficiency, electrify transportation, and implement carbon capture and storage technologies.\n",
      "\n",
      "Furthermore, protecting and reforestation efforts can help remove carbon dioxide from the atmosphere, and sustainable land use practices can help sequester carbon in soils and biomass.\n",
      "\n",
      "However, the window of opportunity for limiting warming to 1.5°C is rapidly closing. The IPCC has warned that if global warming exceeds 1.5°C, the risk of extreme weather events such as heatwaves, droughts, and heavy rainfall increases, and the likelihood of reaching tipping points such as melting glaciers and sea level rise increases.\n",
      "\n",
      "Therefore, it is crucial that we take urgent action now to address climate change and avoid the worst impacts of global warming. This includes implementing policies such as carbon pricing, increasing investment in clean energy, and promoting sustainable development and consumption patterns.\n",
      "\n",
      "I hope this information helps answer your question. Do you have any other questions or concerns about climate change?\n"
     ]
    }
   ],
   "source": [
    "# input_prompt = {\n",
    "#     \"system\": {\n",
    "#         \"content\": \"You are Q&A bot. A highly intelligent system that answers user questions\"\n",
    "#     },\n",
    "#     \"role\": \"user\",\n",
    "#     \"content\": question\n",
    "# }\n",
    "\n",
    "# question = \"Is it still possible to limit warming to 1.5°C?\" #Q1\n",
    "answer = llm(question)\n",
    "# answer = generate_llama2_response(question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08366ebd-7ed5-4a88-8b11-0d5c79ed1127",
   "metadata": {},
   "source": [
    "### How to load an external PDF and do embedding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5303d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"IPCC_AR6_WGIII_FullReport.pdf\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "678c2b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2042 Working Group III contribution to the\n",
      "Sixth Assessment Report of the \n",
      "Intergovernmental Panel on Climate ChangeWGIIIMitigation of Climate ChangeClimate Change 2022\n"
     ]
    }
   ],
   "source": [
    "# check docs length and content\n",
    "print(len(docs), docs[0].page_content[0:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b8268e",
   "metadata": {},
   "source": [
    "We need to store our documents. There are more than 30 vector stores (DBs) supported by LangChain. \n",
    "For this example we will use [Chroma](https://python.langchain.com/docs/integrations/vectorstores/chroma) which is light-weight and in memory so it's easy to get started with.\n",
    "For other vector stores especially if you need to store a large amount of data - see https://python.langchain.com/docs/integrations/vectorstores\n",
    "\n",
    "We will also import the HuggingFaceEmbeddings and RecursiveCharacterTextSplitter to assist in storing the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eecb6a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# embeddings are numerical representations of the question and answer text\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# use a common text splitter to split text into chunks\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d4a17c",
   "metadata": {},
   "source": [
    "To store the documents, we will need to split them into chunks using [`RecursiveCharacterTextSplitter`](https://python.langchain.com/docs/modules/data_connection/document_transformers/text_splitters/recursive_text_splitter) and create vector representations of these chunks using [`HuggingFaceEmbeddings`](https://www.google.com/search?q=langchain+hugging+face+embeddings&sca_esv=572890011&ei=ARUoZaH4LuumptQP48ah2Ac&oq=langchian+hugg&gs_lp=Egxnd3Mtd2l6LXNlcnAiDmxhbmdjaGlhbiBodWdnKgIIADIHEAAYgAQYCjIHEAAYgAQYCjIHEAAYgAQYCjIHEAAYgAQYCjIHEAAYgAQYCjIHEAAYgAQYCjIHEAAYgAQYCjIHEAAYgAQYCjIHEAAYgAQYCjIHEAAYgAQYCkjeHlC5Cli5D3ABeAGQAQCYAV6gAb4CqgEBNLgBAcgBAPgBAcICChAAGEcY1gQYsAPiAwQYACBBiAYBkAYI&sclient=gws-wiz-serp) on them before storing them into our vector database. \n",
    "\n",
    "In general, you should use larger chuck sizes for highly structured text such as code and smaller size for less structured text. You may need to experiment with different chunk sizes and overlap values to find out the best numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc65e161",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# create the vector db to store all the split chunks as embeddings\n",
    "embeddings = HuggingFaceEmbeddings()\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=all_splits,\n",
    "    embedding=embeddings,\n",
    ")\n",
    "# This part is not GPU supported \n",
    "# Slow about 30 mins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f719b9-67ff-4637-8996-133cc1c08724",
   "metadata": {},
   "source": [
    "### How to run Llama2 + pdf (chatClimate)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ad02d7",
   "metadata": {},
   "source": [
    "We then use `RetrievalQA` to retrieve the documents from the vector database and give the model more context on Llama 2, thereby increasing its knowledge.\n",
    "\n",
    "For each question, LangChain performs a semantic similarity search of it in the vector db, then passes the search results as the context to Llama to answer the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "94368852-44d8-4c2a-8208-2c832a972545",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Is it still possible to limit warming to 1.5°C?\" #Q1\n",
    "\n",
    "External_knowledge = vectordb\n",
    "\n",
    "input_prompt = {\n",
    "    \"system\": {\n",
    "        \"content\": \"You are a Q&A bot, an intelligent system that answers user questions ONLY based on the information provided by the user. If you use user information, please indicate the Page and Reference, which are provided below each piece of information. If the information cannot be found in the information provided by the user, please say ’I don’t know’\"\n",
    "    },\n",
    "    \"role\": \"user\", \"content\": [External_knowledge, question]\n",
    "}\n",
    "\n",
    "llm = Replicate(\n",
    "    model=llama2_13b,\n",
    "    model_kwargs={'prompt': f\"{input_prompt}\", \"temperature\": 0.01, \"top_p\": 1, \"max_new_tokens\":5000},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "00e3f72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hello! As a helpful assistant, I'm here to answer your question based on the information provided.\n",
      "\n",
      "According to the information provided, the possibility of limiting warming to 1.5°C is still present, but it will require significant efforts to achieve this goal. The Intergovernmental Panel on Climate Change (IPCC) has outlined several pathways that could lead to limiting global warming to 1.5°C above pre-industrial levels, which include:\n",
      "\n",
      "1. Reducing greenhouse gas emissions by 45% by 2030 and reaching net-zero emissions by 2050.\n",
      "2. Increasing the use of renewable energy sources such as solar and wind power.\n",
      "3. Improving energy efficiency and reducing wasteful consumption.\n",
      "4. Protecting and reforestation efforts to remove carbon dioxide from the atmosphere.\n",
      "\n",
      "However, it is important to note that achieving these goals will require the cooperation and commitment of governments, businesses, and individuals around the world. It will also require significant investments in clean energy technologies and infrastructure, as well as changes in individual behavior and consumer choices.\n",
      "\n",
      "I hope this information helps! If you have any further questions or would like more information, please don't hesitate to ask.\n"
     ]
    }
   ],
   "source": [
    "# use LangChain's RetrievalQA, to associate Llama with the loaded documents stored in the vector db\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever()\n",
    ")\n",
    "\n",
    "question = \"Is it still possible to limit warming to 1.5°C?\" #Q1\n",
    "result = qa_chain({\"query\": question})\n",
    "print(result['result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e63769a",
   "metadata": {},
   "source": [
    "### How to run Llama2 hybird chatClimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "855d8062-4a40-45e9-802a-c4242fe19ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Is it still possible to limit warming to 1.5°C?\" #Q1\n",
    "\n",
    "External_knowledge = vectordb\n",
    "\n",
    "input_prompt = {\n",
    "    \"system\": {\n",
    "        \"content\": \"You are a Q&A bot, an intelligent system that answers user questions based on the information provided by the user above the question and your in-house knowledge. There are 15 pieces of extra information above the user question. Please indicate the Page and Reference, which are provided below each piece of information. Additionally, let us know which part of your answer is from the IPCC information and which part is based on your in-house knowledge by writing either (IPCC AR6) or (Inhouse knowledge). If the information cannot be found in the information provided by the user or your in-house knowledge, please say ’I don’t know’.\"\n",
    "    },\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [question, External_knowledge]\n",
    "}\n",
    "\n",
    "llm = Replicate(\n",
    "    model=llama2_13b,\n",
    "    model_kwargs={'prompt': f\"{input_prompt}\", \"temperature\": 0.01, \"top_p\": 1, \"max_new_tokens\":5000},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cfd1ece9-704e-49a0-b509-1ec9246a3b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hello! As a helpful assistant, I'm here to answer any questions you may have. Based on the information provided, you asked: \"Is it still possible to limit warming to 1.5°C?\"\n",
      "\n",
      "To provide the most accurate answer, I would like to refer to the Intergovernmental Panel on Climate Change (IPCC) Sixth Assessment Report (AR6), which states that limiting global warming to 1.5°C is technically and financially feasible, but it requires significant and rapid reductions in greenhouse gas emissions. The report emphasizes that the window for achieving this goal is rapidly closing (IPCC AR6, p. 3).\n",
      "\n",
      "However, it is important to note that achieving the 1.5°C target will become increasingly challenging as time passes, as the concentration of greenhouse gases in the atmosphere continues to rise. According to the IPCC, the world has already warmed by about 1°C since preindustrial times, and the amount of greenhouse gases in the atmosphere has increased by about 40% since the mid-1800s (IPCC AR6, p. 17).\n",
      "\n",
      "Furthermore, the IPCC reports that there are significant differences between the impacts of 1.5°C and 2°C of warming. For example, at 1.5°C, sea level rise is projected to be around 20-30 cm lower than at 2°C, and the risk of coral reefs dying off is significantly higher at 2°C than at 1.5°C (IPCC AR6, pp. 19-20).\n",
      "\n",
      "In conclusion, while limiting warming to 1.5°C is technically and financially feasible, it requires urgent action and significant reductions in greenhouse gas emissions. The longer we delay taking action, the more difficult it will become to achieve this goal. Therefore, I strongly advise policymakers and other stakeholders to take immediate and drastic measures to reduce emissions and prevent further warming. (IPCC AR6)\n"
     ]
    }
   ],
   "source": [
    "# use LangChain's RetrievalQA, to associate Llama with the loaded documents stored in the vector db\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    # chain_type_kwargs={\"prompt\": f\"{input_prompt}\"},\n",
    ")\n",
    "\n",
    "question = \"Is it still possible to limit warming to 1.5°C?\" #Q1\n",
    "result = qa_chain({\"query\": question})\n",
    "print(result['result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb60995-d509-441d-9038-b8b1e8b9e67a",
   "metadata": {},
   "source": [
    "### How does ChatGPT3.5 answer?\n",
    "[https://chat.openai.com/share/17cf5cc6-50db-4547-a56f-18756a974622](https://chat.openai.com/share/17cf5cc6-50db-4547-a56f-18756a974622)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50bc472-23c7-4197-ae78-727409031904",
   "metadata": {},
   "source": [
    "### How to load multiple PDFs?\n",
    "\n",
    "We will use PyPDF Directory to load PDFs from directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b853bc0-3846-4271-b74d-e07a3562b198",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "\n",
    "loader = PyPDFDirectoryLoader(\"yl_External_PDFs/\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9931052-bbe1-4372-89f2-e084d1ec8816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check docs length and content\n",
    "print(len(docs), docs[0].page_content[0:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94a2cb3-90a4-493d-9fda-1a338371627f",
   "metadata": {},
   "source": [
    "To store the documents, we will need to split them into chunks using [`RecursiveCharacterTextSplitter`](https://python.langchain.com/docs/modules/data_connection/document_transformers/text_splitters/recursive_text_splitter) and create vector representations of these chunks using [`HuggingFaceEmbeddings`](https://www.google.com/search?q=langchain+hugging+face+embeddings&sca_esv=572890011&ei=ARUoZaH4LuumptQP48ah2Ac&oq=langchian+hugg&gs_lp=Egxnd3Mtd2l6LXNlcnAiDmxhbmdjaGlhbiBodWdnKgIIADIHEAAYgAQYCjIHEAAYgAQYCjIHEAAYgAQYCjIHEAAYgAQYCjIHEAAYgAQYCjIHEAAYgAQYCjIHEAAYgAQYCjIHEAAYgAQYCjIHEAAYgAQYCjIHEAAYgAQYCkjeHlC5Cli5D3ABeAGQAQCYAV6gAb4CqgEBNLgBAcgBAPgBAcICChAAGEcY1gQYsAPiAwQYACBBiAYBkAYI&sclient=gws-wiz-serp) on them before storing them into our vector database. \n",
    "\n",
    "In general, you should use larger chuck sizes for highly structured text such as code and smaller size for less structured text. You may need to experiment with different chunk sizes and overlap values to find out the best numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388de72c-a18a-4f60-b380-870768c83a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# create the vector db to store all the split chunks as embeddings\n",
    "embeddings = HuggingFaceEmbeddings()\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=all_splits,\n",
    "    embedding=embeddings,\n",
    ") \n",
    "# slow \n",
    "# about 30 mins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a063461-88da-4d00-9a72-6acec193ef06",
   "metadata": {},
   "source": [
    "We then use ` RetrievalQA` to retrieve the documents from the vector database and give the model more context on Llama 2, thereby increasing its knowledge.\n",
    "\n",
    "For each question, LangChain performs a semantic similarity search of it in the vector db, then passes the search results as the context to Llama to answer the question."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
